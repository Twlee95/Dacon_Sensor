{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabnet with extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler, Normalizer, RobustScaler, StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold      # St for class\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.metrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set visible device\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1, 2, 3\"\n",
    "\n",
    "CONFIG = {\n",
    "    'n_worker':16,\n",
    "    # Tabnet model\n",
    "    'epochs' : 1000,\n",
    "    'patience' : 100,\n",
    "    'learning_rate':2e-3,\n",
    "    'weight_decay':1e-5,\n",
    "    'threshold':0.5,\n",
    "    'seed':42,\n",
    "    'fold':5\n",
    "}\n",
    "\n",
    "# seed setting function\n",
    "def seed_everything(seed:int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CONFIG['seed']) # Seed setting\n",
    "\n",
    "# tabnet params\n",
    "tabnet_params = dict(\n",
    "    n_d = 64,   # 8 to 64\n",
    "    n_a = 128,  # n_d = n_a usally good\n",
    "    n_steps = 3,\n",
    "    gamma = 1.3,\n",
    "    lambda_sparse = 0,\n",
    "    n_independent = 2,\n",
    "    n_shared = 1,\n",
    "    optimizer_fn = optim.Adam,\n",
    "    optimizer_params = dict(lr = CONFIG['learning_rate'], weight_decay = CONFIG['weight_decay']),\n",
    "    mask_type = \"entmax\",\n",
    "    scheduler_params = dict(\n",
    "        mode = \"min\", patience = 10, min_lr = 1e-5, factor = 0.9),\n",
    "    scheduler_fn = ReduceLROnPlateau,\n",
    "    seed = CONFIG[\"seed\"],\n",
    "    verbose = 15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Norm \n",
    "def norm_transform(datatype, data, scaler_name='z-score', scaler=None):\n",
    "    scaler_dict = {\n",
    "        'z-score':StandardScaler(),\n",
    "        'minmax':MinMaxScaler(),\n",
    "        'maxabs':MaxAbsScaler(),\n",
    "        'robust':RobustScaler(),\n",
    "        'norm':Normalizer()\n",
    "    }\n",
    "    \n",
    "    # use only train\n",
    "    if not datatype==\"test\":\n",
    "        scaler = scaler_dict[scaler_name]\n",
    "        scaled_train = scaler.fit_transform(data)\n",
    "        return scaled_train, scaler\n",
    "    else:\n",
    "        scaled_test = scaler.transform(data)\n",
    "        return scaled_test\n",
    "\n",
    "# ============= pca \n",
    "def pca_transform(datatype, data, n_comp=300, pca=None):\n",
    "    if not datatype==\"test\":\n",
    "        pca = PCA(n_components=n_comp, random_state=CONFIG[\"seed\"])\n",
    "        pca_train = pca.fit_transform(data)\n",
    "        print(f\"with {n_comp} components, pca variance ratio : {sum(pca.explained_variance_ratio_)}\")\n",
    "        return pca_train, pca\n",
    "    else:\n",
    "        pca_test = pca.transform(data)\n",
    "        return pca_test\n",
    "\n",
    "\n",
    "def lg_nrmse(gt, preds):\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14): # ignore 'ID'\n",
    "        rmse = mean_squared_error(gt[:,idx], preds[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:14])\n",
    "    return score\n",
    "\n",
    "    \n",
    "class NRMSE(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"NormRMSE\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        nrmse = lg_nrmse(y_true, y_score)\n",
    "        return nrmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 382.77832| val_0_rmse: 350.20084| val_0_mse: 122640.62865| val_0_NormRMSE: 858.85796|  0:00:01s\n",
      "epoch 15 | loss: 1.57123 | val_0_rmse: 2.3921  | val_0_mse: 5.72217 | val_0_NormRMSE: 4.04192 |  0:00:21s\n",
      "epoch 30 | loss: 1.42931 | val_0_rmse: 1.21813 | val_0_mse: 1.48385 | val_0_NormRMSE: 2.03212 |  0:00:41s\n",
      "epoch 45 | loss: 1.15811 | val_0_rmse: 1.24842 | val_0_mse: 1.55856 | val_0_NormRMSE: 2.02706 |  0:01:02s\n",
      "epoch 60 | loss: 0.94341 | val_0_rmse: 1.30655 | val_0_mse: 1.70706 | val_0_NormRMSE: 2.06667 |  0:01:23s\n",
      "epoch 75 | loss: 0.8046  | val_0_rmse: 1.32967 | val_0_mse: 1.76803 | val_0_NormRMSE: 2.07642 |  0:01:44s\n",
      "epoch 90 | loss: 0.70645 | val_0_rmse: 1.3353  | val_0_mse: 1.78302 | val_0_NormRMSE: 2.07545 |  0:02:04s\n",
      "epoch 105| loss: 0.6424  | val_0_rmse: 1.347   | val_0_mse: 1.8144  | val_0_NormRMSE: 2.07877 |  0:02:25s\n",
      "epoch 120| loss: 0.59632 | val_0_rmse: 1.35713 | val_0_mse: 1.8418  | val_0_NormRMSE: 2.09307 |  0:02:45s\n",
      "\n",
      "Early stopping occurred at epoch 131 with best_epoch = 31 and best_val_0_NormRMSE = 2.01744\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ./Tabnet_models/./tabnet_fold1.zip\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 382.76289| val_0_rmse: 93.92091| val_0_mse: 8821.13821| val_0_NormRMSE: 256.12068|  0:00:01s\n",
      "epoch 15 | loss: 1.54533 | val_0_rmse: 1.49111 | val_0_mse: 2.2234  | val_0_NormRMSE: 2.54586 |  0:00:22s\n",
      "epoch 30 | loss: 1.37438 | val_0_rmse: 1.27237 | val_0_mse: 1.61893 | val_0_NormRMSE: 2.04884 |  0:00:42s\n",
      "epoch 45 | loss: 1.16914 | val_0_rmse: 1.31373 | val_0_mse: 1.72588 | val_0_NormRMSE: 2.07689 |  0:01:03s\n",
      "epoch 60 | loss: 0.96609 | val_0_rmse: 1.35249 | val_0_mse: 1.82922 | val_0_NormRMSE: 2.09554 |  0:01:24s\n",
      "epoch 75 | loss: 0.82853 | val_0_rmse: 1.38914 | val_0_mse: 1.92971 | val_0_NormRMSE: 2.11421 |  0:01:45s\n",
      "epoch 90 | loss: 0.72832 | val_0_rmse: 1.40196 | val_0_mse: 1.9655  | val_0_NormRMSE: 2.12096 |  0:02:05s\n",
      "epoch 105| loss: 0.65591 | val_0_rmse: 1.40955 | val_0_mse: 1.98684 | val_0_NormRMSE: 2.12263 |  0:02:26s\n",
      "epoch 120| loss: 0.60611 | val_0_rmse: 1.42177 | val_0_mse: 2.02142 | val_0_NormRMSE: 2.12991 |  0:02:47s\n",
      "\n",
      "Early stopping occurred at epoch 125 with best_epoch = 25 and best_val_0_NormRMSE = 2.04733\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ./Tabnet_models/./tabnet_fold2.zip\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 382.93008| val_0_rmse: 128.08436| val_0_mse: 16405.60213| val_0_NormRMSE: 360.3259|  0:00:01s\n",
      "epoch 15 | loss: 1.5807  | val_0_rmse: 1.59158 | val_0_mse: 2.53313 | val_0_NormRMSE: 2.5105  |  0:00:22s\n",
      "epoch 30 | loss: 1.44022 | val_0_rmse: 1.23053 | val_0_mse: 1.51421 | val_0_NormRMSE: 2.03722 |  0:00:42s\n",
      "epoch 45 | loss: 1.18652 | val_0_rmse: 1.26374 | val_0_mse: 1.59703 | val_0_NormRMSE: 2.05172 |  0:01:03s\n",
      "epoch 60 | loss: 0.97765 | val_0_rmse: 1.32734 | val_0_mse: 1.76182 | val_0_NormRMSE: 2.08365 |  0:01:24s\n",
      "epoch 75 | loss: 0.81487 | val_0_rmse: 1.35922 | val_0_mse: 1.84749 | val_0_NormRMSE: 2.10101 |  0:01:45s\n",
      "epoch 90 | loss: 0.72803 | val_0_rmse: 1.36771 | val_0_mse: 1.87063 | val_0_NormRMSE: 2.1164  |  0:02:05s\n",
      "epoch 105| loss: 0.64936 | val_0_rmse: 1.43261 | val_0_mse: 2.05238 | val_0_NormRMSE: 2.17947 |  0:02:26s\n",
      "epoch 120| loss: 0.60115 | val_0_rmse: 1.37559 | val_0_mse: 1.89224 | val_0_NormRMSE: 2.1096  |  0:02:47s\n",
      "epoch 135| loss: 0.56745 | val_0_rmse: 1.37421 | val_0_mse: 1.88844 | val_0_NormRMSE: 2.10457 |  0:03:07s\n",
      "\n",
      "Early stopping occurred at epoch 138 with best_epoch = 38 and best_val_0_NormRMSE = 2.02634\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ./Tabnet_models/./tabnet_fold3.zip\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 382.97175| val_0_rmse: 112.96717| val_0_mse: 12761.58151| val_0_NormRMSE: 230.72009|  0:00:01s\n",
      "epoch 15 | loss: 1.58917 | val_0_rmse: 1.75108 | val_0_mse: 3.06627 | val_0_NormRMSE: 2.83575 |  0:00:22s\n",
      "epoch 30 | loss: 1.50426 | val_0_rmse: 1.2239  | val_0_mse: 1.49793 | val_0_NormRMSE: 2.02909 |  0:00:43s\n",
      "epoch 45 | loss: 1.29235 | val_0_rmse: 1.24583 | val_0_mse: 1.5521  | val_0_NormRMSE: 2.04171 |  0:01:03s\n",
      "epoch 60 | loss: 1.03532 | val_0_rmse: 1.28269 | val_0_mse: 1.64529 | val_0_NormRMSE: 2.05265 |  0:01:24s\n",
      "epoch 75 | loss: 0.85899 | val_0_rmse: 1.33301 | val_0_mse: 1.77691 | val_0_NormRMSE: 2.09039 |  0:01:45s\n",
      "epoch 90 | loss: 0.75876 | val_0_rmse: 1.34507 | val_0_mse: 1.80922 | val_0_NormRMSE: 2.09307 |  0:02:05s\n",
      "epoch 105| loss: 0.69207 | val_0_rmse: 1.40631 | val_0_mse: 1.97772 | val_0_NormRMSE: 2.15647 |  0:02:26s\n",
      "epoch 120| loss: 0.63512 | val_0_rmse: 1.38347 | val_0_mse: 1.91398 | val_0_NormRMSE: 2.11868 |  0:02:46s\n",
      "\n",
      "Early stopping occurred at epoch 128 with best_epoch = 28 and best_val_0_NormRMSE = 2.02368\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ./Tabnet_models/./tabnet_fold4.zip\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 382.4847| val_0_rmse: 103.07584| val_0_mse: 10624.62841| val_0_NormRMSE: 297.55174|  0:00:01s\n",
      "epoch 15 | loss: 1.57086 | val_0_rmse: 2.17717 | val_0_mse: 4.74007 | val_0_NormRMSE: 3.46582 |  0:00:22s\n",
      "epoch 30 | loss: 1.49627 | val_0_rmse: 1.24923 | val_0_mse: 1.56059 | val_0_NormRMSE: 2.03638 |  0:00:42s\n",
      "epoch 45 | loss: 1.33998 | val_0_rmse: 1.28098 | val_0_mse: 1.6409  | val_0_NormRMSE: 2.05883 |  0:01:03s\n",
      "epoch 60 | loss: 1.10611 | val_0_rmse: 1.30685 | val_0_mse: 1.70787 | val_0_NormRMSE: 2.06753 |  0:01:24s\n",
      "epoch 75 | loss: 0.91257 | val_0_rmse: 1.36014 | val_0_mse: 1.84997 | val_0_NormRMSE: 2.10267 |  0:01:44s\n",
      "epoch 90 | loss: 0.79727 | val_0_rmse: 1.36882 | val_0_mse: 1.87367 | val_0_NormRMSE: 2.10265 |  0:02:05s\n",
      "epoch 105| loss: 0.71275 | val_0_rmse: 1.37995 | val_0_mse: 1.90427 | val_0_NormRMSE: 2.11161 |  0:02:26s\n",
      "epoch 120| loss: 0.65091 | val_0_rmse: 1.38196 | val_0_mse: 1.90983 | val_0_NormRMSE: 2.10875 |  0:02:46s\n",
      "\n",
      "Early stopping occurred at epoch 130 with best_epoch = 30 and best_val_0_NormRMSE = 2.03638\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ./Tabnet_models/./tabnet_fold5.zip\n"
     ]
    }
   ],
   "source": [
    "input_dir = '../../../dataset/'\n",
    "TRAIN_DATA_PATH = input_dir+'train_features.csv'\n",
    "TEST_DATA_PATH = input_dir+'test_features.csv'\n",
    "SAMPLE_SUB_PATH = input_dir+'sample_submission.csv'\n",
    "\n",
    "MODEL_DIR_NAME = \"./Tabnet_models\"\n",
    "SCALER_PATH = os.path.join(MODEL_DIR_NAME, \"x_scaler.pkl\")\n",
    "\n",
    "if not os.path.exists(MODEL_DIR_NAME):\n",
    "    os.makedirs(MODEL_DIR_NAME)\n",
    "\n",
    "n_targets = 14\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "df_test = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "df_train = df_train.drop(labels=['X_10', 'X_11'], axis=1)\n",
    "df_test = df_test.drop(labels=['X_10', 'X_11', 'seat_kurtosis', 'area_kurtosis'], axis=1)\n",
    "\n",
    "X_features, y_features = df_train.iloc[:, 1:-14].values, df_train.iloc[:, -14:].values\n",
    "X_test_features = df_test.iloc[:, 1:].values\n",
    "# X_norm_features, scaler = norm_transform(\"train\", X_features, \"z-score\")\n",
    "# with open(SCALER_PATH, \"wb\") as fw:\n",
    "#     pickle.dump(scaler, fw)\n",
    "# X_test_norm_features = norm_transform(\"test\", X_test_features, \"z-score\", scaler)\n",
    "\n",
    "kf = KFold(n_splits=CONFIG['fold'], random_state=CONFIG['seed'], shuffle=True)\n",
    "avg_loss, avg_nrmse = 0, 0\n",
    "\n",
    "LOG_PATH = os.path.join(MODEL_DIR_NAME, \"log.txt\")\n",
    "\n",
    "with open(LOG_PATH, \"w\") as fw:\n",
    "    fw.write(\"Tabnet model ==\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_features)):\n",
    "    with open(LOG_PATH, \"a\") as fa:\n",
    "        fa.write(f\": ========= FOLD {fold+1} ========= :\\n\")\n",
    "\n",
    "    model = TabNetRegressor(**tabnet_params)\n",
    "    model.fit(X_train=X_features[train_idx], y_train=y_features[train_idx],\n",
    "                eval_set=[(X_features[test_idx],y_features[test_idx])],\n",
    "                loss_fn=nn.MSELoss(),\n",
    "                max_epochs=CONFIG['epochs'], patience=CONFIG['patience'], \n",
    "                eval_metric=['rmse', 'mse', NRMSE])\n",
    "    model_name = f'./tabnet_fold{fold+1}'\n",
    "    model_path = os.path.join(MODEL_DIR_NAME, model_name)\n",
    "    model.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "preds_reg = np.zeros((len(df_test), n_targets))\n",
    "\n",
    "for fold in range(CONFIG['fold']):\n",
    "    model_path = os.path.join(MODEL_DIR_NAME, f\"tabnet_fold{fold+1}.zip\")\n",
    "    infer_model = TabNetRegressor(**tabnet_params)\n",
    "    infer_model.load_model(model_path)\n",
    "\n",
    "    preds_reg += infer_model.predict(X_test_features)\n",
    "\n",
    "preds_reg /= CONFIG['fold']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "SAMPLE_SUB_PATH = input_dir+'sample_submission.csv'\n",
    "submit = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "submit.iloc[:, 1:] = preds_reg\n",
    "submit.to_csv('./tabnet_ext_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lg-sensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b5469814fc745b6ebb6b6949bbf995afe923901249078e507e0034822b46ec0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
