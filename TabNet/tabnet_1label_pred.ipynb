{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler, Normalizer, RobustScaler, StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold      # St for class\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.metrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set visible device\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1, 2, 3\"\n",
    "\n",
    "CONFIG = {\n",
    "    'n_worker':16,\n",
    "    # Tabnet model\n",
    "    'epochs' : 100,\n",
    "    'patience' : 20,\n",
    "    'learning_rate':2e-3,\n",
    "    'weight_decay':1e-5,\n",
    "    'threshold':0.5,\n",
    "    'seed':42,\n",
    "    'fold':5\n",
    "}\n",
    "\n",
    "# seed setting function\n",
    "def seed_everything(seed:int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CONFIG['seed']) # Seed setting\n",
    "\n",
    "# tabnet params\n",
    "tabnet_params = dict(\n",
    "    n_d = 64,   # 8 to 64\n",
    "    n_a = 128,  # n_d = n_a usally good\n",
    "    n_steps = 3,\n",
    "    gamma = 1.3,\n",
    "    lambda_sparse = 0,\n",
    "    n_independent = 2,\n",
    "    n_shared = 1,\n",
    "    optimizer_fn = optim.Adam,\n",
    "    optimizer_params = dict(lr = CONFIG['learning_rate'], weight_decay = CONFIG['weight_decay']),\n",
    "    mask_type = \"entmax\",\n",
    "    scheduler_params = dict(\n",
    "        mode = \"min\", patience = 5, min_lr = 1e-5, factor = 0.9),\n",
    "    scheduler_fn = ReduceLROnPlateau,\n",
    "    seed = CONFIG[\"seed\"],\n",
    "    verbose = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Norm \n",
    "def norm_transform(datatype, data, scaler_name='z-score', scaler=None):\n",
    "    scaler_dict = {\n",
    "        'z-score':StandardScaler(),\n",
    "        'minmax':MinMaxScaler(),\n",
    "        'maxabs':MaxAbsScaler(),\n",
    "        'robust':RobustScaler(),\n",
    "        'norm':Normalizer()\n",
    "    }\n",
    "    \n",
    "    # use only train\n",
    "    if not datatype==\"test\":\n",
    "        scaler = scaler_dict[scaler_name]\n",
    "        scaled_train = scaler.fit_transform(data)\n",
    "        return scaled_train, scaler\n",
    "    else:\n",
    "        scaled_test = scaler.transform(data)\n",
    "        return scaled_test\n",
    "\n",
    "# ============= pca \n",
    "def pca_transform(datatype, data, n_comp=300, pca=None):\n",
    "    if not datatype==\"test\":\n",
    "        pca = PCA(n_components=n_comp, random_state=CONFIG[\"seed\"])\n",
    "        pca_train = pca.fit_transform(data)\n",
    "        print(f\"with {n_comp} components, pca variance ratio : {sum(pca.explained_variance_ratio_)}\")\n",
    "        return pca_train, pca\n",
    "    else:\n",
    "        pca_test = pca.transform(data)\n",
    "        return pca_test\n",
    "\n",
    "\n",
    "def lg_nrmse(gt, preds):\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14): # ignore 'ID'\n",
    "        rmse = mean_squared_error(gt[:,idx], preds[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:14])\n",
    "    return score\n",
    "\n",
    "    \n",
    "class NRMSE(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"NormRMSE\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        nrmse = lg_nrmse(y_true, y_score)\n",
    "        return nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TabNetRegressor() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lab\\JupyterProjects_lab\\lg_sensor\\tabnet_1label_pred.ipynb 셀 4\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     fa\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: ========= FOLD \u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m ========= :\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m14\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     model \u001b[39m=\u001b[39m TabNetRegressor(n_d \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m,   \u001b[39m# 8 to 64\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     n_a \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m,  \u001b[39m# n_d = n_a usally good\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     n_steps \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     gamma \u001b[39m=\u001b[39;49m \u001b[39m1.3\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     lambda_sparse \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     n_independent \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     n_shared \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     optimizer_fn \u001b[39m=\u001b[39;49m optim\u001b[39m.\u001b[39;49mAdam,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     optimizer_params \u001b[39m=\u001b[39;49m \u001b[39mdict\u001b[39;49m(lr \u001b[39m=\u001b[39;49m CONFIG[\u001b[39m'\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m'\u001b[39;49m], weight_decay \u001b[39m=\u001b[39;49m CONFIG[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     mask_type \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mentmax\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     scheduler_params \u001b[39m=\u001b[39;49m \u001b[39mdict\u001b[39;49m(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m         mode \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m\"\u001b[39;49m, patience \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, min_lr \u001b[39m=\u001b[39;49m \u001b[39m1e-5\u001b[39;49m, factor \u001b[39m=\u001b[39;49m \u001b[39m0.9\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     scheduler_fn \u001b[39m=\u001b[39;49m ReduceLROnPlateau,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     seed \u001b[39m=\u001b[39;49m CONFIG[\u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     verbose \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train\u001b[39m=\u001b[39mX_train_norm_features[train_idx], y_train\u001b[39m=\u001b[39mdf_train_y[i,train_idx],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m                 eval_set\u001b[39m=\u001b[39m[(X_train_norm_features[test_idx],df_train_y[test_idx])],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m                 max_epochs\u001b[39m=\u001b[39mCONFIG[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m], patience\u001b[39m=\u001b[39mCONFIG[\u001b[39m'\u001b[39m\u001b[39mpatience\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m                 eval_metric\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, NRMSE])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lab/JupyterProjects_lab/lg_sensor/tabnet_1label_pred.ipynb#W3sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(MODEL_DIR_NAME, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./tabnet_mode\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_fold\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: TabNetRegressor() takes no arguments"
     ]
    }
   ],
   "source": [
    "MODEL_DIR_NAME = \"./Tabnet_models\"\n",
    "\n",
    "TABNET_OUTPUT_DIR_NAME = \"./tabnet_outputs\"\n",
    "SCALER_PATH = os.path.join(TABNET_OUTPUT_DIR_NAME, \"x_scaler.pkl\")\n",
    "\n",
    "if not os.path.exists(MODEL_DIR_NAME):\n",
    "    os.makedirs(MODEL_DIR_NAME)\n",
    "\n",
    "n_targets = 14\n",
    "\n",
    "df_train = pd.read_csv(\"datasets/train.csv\")\n",
    "df_test = pd.read_csv(\"datasets/test.csv\")\n",
    "\n",
    "df_train = df_train.drop('X_10', axis=1)\n",
    "df_train = df_train.drop('X_11', axis=1)\n",
    "df_test = df_test.drop('X_10', axis=1)\n",
    "df_test = df_test.drop('X_11', axis=1)\n",
    "\n",
    "\n",
    "# train_yhat_data = pd.read_csv(\"tabnet_outputs/tabnet_train_yhat.csv\")\n",
    "# test_yhat_data = pd.read_csv(\"tabnet_outputs/tabnet_test_yhat.csv\")\n",
    "# train_yhat_data = train_yhat_data.values\n",
    "# test_yhat_data = test_yhat_data.values\n",
    "# X_train_features = np.load(\"autoencoder_output/autoencoder_feature.npy\")\n",
    "# X_test_features = np.load(\"autoencoder_output/autoencoder_feature_test.npy\")\n",
    "# X_train_features = np.concatenate((X_train_features,train_yhat_data),axis=1)\n",
    "# X_test_features = np.concatenate((X_test_features,test_yhat_data),axis=1)\n",
    "\n",
    "df_train_x = df_train.iloc[:,1:-14].values\n",
    "df_train_y = df_train.iloc[:,-14:].values\n",
    "\n",
    "\n",
    "X_test_features =  df_test.iloc[:,1:].values\n",
    "X_train_norm_features, scaler = norm_transform(\"train\", df_train_x, \"minmax\")\n",
    "\n",
    "\n",
    "with open(SCALER_PATH, \"wb\") as fw:\n",
    "    pickle.dump(scaler, fw)\n",
    "X_test_norm_features = norm_transform(\"test\", X_test_features, \"minmax\", scaler)\n",
    "\n",
    "kf = KFold(n_splits=CONFIG['fold'], random_state=CONFIG['seed'], shuffle=True)\n",
    "\n",
    "avg_loss, avg_nrmse = 0, 0\n",
    "LOG_PATH = os.path.join(MODEL_DIR_NAME, \"log.txt\")\n",
    "with open(LOG_PATH, \"w\") as fw:\n",
    "    fw.write(\"Tabnet model ==\")\n",
    "\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train_norm_features)):\n",
    "    with open(LOG_PATH, \"a\") as fa:\n",
    "        fa.write(f\": ========= FOLD {fold+1} ========= :\\n\")\n",
    "    for i in range(14):\n",
    "        \n",
    "        model = TabNetRegressor(**tabnet_params)\n",
    "\n",
    "        model.fit(X_train=X_train_norm_features[train_idx], y_train=df_train_y[i,train_idx],\n",
    "                    eval_set=[(X_train_norm_features[test_idx],df_train_y[test_idx])],\n",
    "                    max_epochs=CONFIG['epochs'], patience=CONFIG['patience'], \n",
    "                    eval_metric=['rmse', 'mse', NRMSE])\n",
    "        \n",
    "        model_path = os.path.join(MODEL_DIR_NAME, f'./tabnet_mode{i+1}_fold{fold+1}')\n",
    "\n",
    "        model.save_model(model_path)\n",
    "        del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test y_hat 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "preds_reg = np.zeros((len(df_test), 1))\n",
    "epreds_reg = np.zeros((len(df_test), 14))\n",
    "\n",
    "for n_model in range(14):\n",
    "    \n",
    "    for fold in range(CONFIG['fold']):\n",
    "        model_path = os.path.join(MODEL_DIR_NAME, f'./tabnet_model{n_model+1}_fold{fold+1}')\n",
    "        infer_model = TabNetRegressor(**tabnet_params)\n",
    "        infer_model.load_model(model_path)\n",
    "\n",
    "        preds_reg += infer_model.predict(X_test_norm_features)\n",
    "    preds_reg /= CONFIG['fold']\n",
    "    \n",
    "    if n_model == 0:\n",
    "        epreds_reg[:,n_model] = preds_reg\n",
    "    else:\n",
    "        epreds_reg = np.concat([epreds_reg,preds_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SUB_PATH = TABNET_OUTPUT_DIR_NAME+'/sample_submission.csv'\n",
    "submit = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "submit.iloc[:, 1:] = epreds_reg\n",
    "submit.to_csv('./tabnet_outputs/tabnet_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('taewon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "013403e7ebf8f35ee0411721c7e4b108aa3c3f8cb903b89610d110413a68ec3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
